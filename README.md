# VA-chatbot

This repo contains the code I wrote to build a simple chatbot agent with quantized Llama2 based off data from https://www.va.gov/ that can be run locally.

The app has been tested on a MacBook Pro with 16GB CPU RAM with M1 chip.

An example of usage of the modules can be found in the notebook ```chatbot_example.ipynb```.

The app can be run with chainlit ```run ask.py```, after installing dependencies in ```requirements.txt``` locally. However, the response can be slow.

An example interface for the chatbot when deployed locally:
![alt text](https://github.com/hozh3497/"VA-chatbot/blob/main/Screenshot\ 2023-11-20\ at\ 7.26.52\ PM.png"?raw=true)
